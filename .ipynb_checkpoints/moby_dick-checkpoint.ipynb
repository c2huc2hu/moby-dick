{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1215235,)\n",
      "(1215235, 1, 71)\n",
      "(75952, 16) (75952, 16, 71)\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_SIZE = 32\n",
    "\n",
    "# character level language model\n",
    "# text = \"abc abcd abcdef abcdefghijk abc ab abc abc abcd ab\" # sample input for testing\n",
    "mobydick = open('whale2.txt')\n",
    "text = mobydick.read()\n",
    "\n",
    "# one-hot code the text\n",
    "filter_chars = 10 # filter out the least used characters\n",
    "chars = ''' etaonsihrldumcwgf,ypbvk.-\\n;I\"'ATS!HBWEqNCPx?OLjRFMDGzYQJU():KV1028573*4Z69X_$][&'''\n",
    "char_to_idx = dict(zip(chars[:-filter_chars], range(len(chars))))\n",
    "idx_to_char = dict(zip(range(len(chars)), chars[:-filter_chars]))\n",
    "input_ = np.array([char_to_idx.get(ch, 0) for ch in text], dtype=np.int32)\n",
    "output = keras.utils.to_categorical(input_[1:], 71)\n",
    "output = np.expand_dims(output, axis=1)\n",
    "input_ = input_[:-1]\n",
    "print(input_.shape)\n",
    "print(output.shape)\n",
    "\n",
    "# splice the full sequence into shorter sequences for training\n",
    "training_seq_len = 16\n",
    "if len(input_) % training_seq_len == 0:\n",
    "    np.append(input_, 0)\n",
    "training_input = input_[:len(input_) // training_seq_len * training_seq_len].reshape(\n",
    "    (-1, training_seq_len))\n",
    "training_output = output[:len(input_) // training_seq_len * training_seq_len,:,:].reshape(\n",
    "    (-1, training_seq_len, 71))\n",
    "\n",
    "print(training_input.shape, training_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (1, None, 16)             1136      \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (1, None, 32)             4704      \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (1, None, 32)             6240      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (1, None, 71)             2343      \n",
      "=================================================================\n",
      "Total params: 14,423\n",
      "Trainable params: 14,423\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(71, 16, batch_input_shape=(1, None)))\n",
    "for i in range(2):\n",
    "    model.add(keras.layers.GRU(\n",
    "        HIDDEN_SIZE, return_sequences=True, stateful=True))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Dense(len(chars) - filter_chars, activation='softmax')))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(training_input, training_output, batch_size=1,\n",
    "          epochs=30, shuffle=False) # , validation_data=(input_, output), validation_freq=10)\n",
    "model.save(\n",
    "    './moby-dick.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " etaonsihrldumcwgf,ypbvk.-\n",
      ";I\"'ATS!HBWEqNCPx?OLjRFMDGzYQJU():KV1028573*4Z69X_[$]&\n",
      "['\\n', ' ', '!', '\"', '$', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'] 81\n"
     ]
    }
   ],
   "source": [
    "# grab descriptive statistics about the corpus\n",
    "file = open('whale2.txt')\n",
    "full_text = file.read()\n",
    "import collections\n",
    "\n",
    "character_set = set(full_text)\n",
    "character_counts = collections.Counter(full_text)\n",
    "print(''.join(([k for k, v in character_counts.most_common()])))\n",
    "print(sorted(list(character_set)), len(character_set)) # 81 unique characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "(1, 3, 71)\n",
      "['b', 'c', ' ']\n"
     ]
    }
   ],
   "source": [
    "# test inference\n",
    "model.reset_states()\n",
    "test_input = np.array([char_to_idx.get(ch, 0) for ch in 'abc'], dtype=np.int32)\n",
    "test_input = np.expand_dims(test_input, axis=0)\n",
    "result = model.predict(test_input)\n",
    "result_text = np.argmax(result, axis=2)\n",
    "print([idx_to_char[ch] for ch in result_text.flatten().tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def infer(ch):\n",
    "    '''predict the next character given the previous one'''\n",
    "    test_input = np.array([char_to_idx.get(ch, 0)])\n",
    "    test_input = np.expand_dims(test_input, axis=0)\n",
    "    result = model.predict(test_input)\n",
    "    result_text = np.argmax(result, axis=2)\n",
    "    return idx_to_char[result_text.flatten()[0]]\n",
    "\n",
    "infer('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'infer_and_score.py', 'moby-dick.h5', 'moby_dick.ipynb', 'Untitled.ipynb', 'whale2.txt']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())\n",
    "keras.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
